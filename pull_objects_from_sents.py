# -*- coding: utf-8 -*-
"""Pull Objects Out of Sentences.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nj2oWek9NOLO57ZvMMs-MYt0i2xyAOd6
"""

# Install/Setup Spacy Components and Language Model
# IF NEEDED
#Functions from external python
#%run '/content/drive/My Drive/Colab Notebooks/functions.py'
!pip install -U spacy 

# Don't forget to restart runtime
!python -m spacy download en_core_web_lg
!python -m spacy download en_core_web_trf

import spacy

# Install/Setup Gensim Components
import gensim, logging
from gensim.models import Word2Vec
from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors
# Install sutime from Stanford NLP library
!pip install sutime
!sudo apt-get install maven
# Install Java dependencies
!mvn dependency:copy-dependencies -DoutputDirectory=./jars -f $(python3 -c 'import importlib; import pathlib; print(pathlib.Path(importlib.util.find_spec("sutime").origin).parent / "pom.xml")')
import datetime
from sutime import SUTime
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
 
# Setup Language Model
#lang_model = spacy.load("en_core_web_lg")
lang_model = spacy.load("en_core_web_trf")

# Merge noun phrases and entities for easier analysis
lang_model.add_pipe('merge_entities')
lang_model.add_pipe('sentencizer')

# LOAD HTML INTO STRING FROM FILE...
url = 'http://fox13now.com/2013/12/30/new-year-new-laws-obamacare-pot-guns-and-drones/'
article = Article(url)

# download article
article.download()
article.html

#parse article -- important!
article.parse()

#article date of publication
publish_date = article.publish_date

#article text
doc_text = article.text

#article title
doc_title = article.title
base_date = publish_date
article_lang_model = lang_model(doc_text)

article_sentences = []
for sent in article_lang_model.sents:
  article_sentences.append(sent)

for s in article_sentences:
  print(s)

sent_no = 0
for sent in article_lang_model.sents:
      sent_no += 1
      for token in sent:
            #print(token.text)
            head_token = ""
            dep_date = "2021-01-01"
            # We have an attribute and direct object, so check for subject
            if token.dep_ in ("attr", "dobj"): 
                subj = [w for w in token.head.lefts if w.dep_ == "nsubj"]
                if subj:
                    head_token = subj[0]
                    print(head_token)
            
            # We have a prepositional object with a preposition
            #elif token.dep_ == "pobj" and token.head.dep_ == "prep":
            #    head_token = token.text
            #    print(head_token)
           
            # We have an adjective object with an adjective
            #elif token.dep_ in ("nummod", "amod", "npadvmod"):
            #    head_token = token.text
            #    print(head_token)

sent_no = 0
for sent in article_lang_model.sents:
      sent_no += 1
      for token in sent:
            #print(token.text)
            head_token = ""
            dep_date = "2021-01-01"
            # We have an attribute and direct object, so check for subject
            #if token.dep_ in ("attr", "dobj"): 
            #    subj = [w for w in token.head.lefts if w.dep_ == "nsubj"]
                #if subj:
                #    head_token = subj[0]
                #    print(head_token)
            
            # We have a prepositional object with a preposition
            if token.dep_ == "pobj" and token.head.dep_ == "prep":
                head_token = token.text
                print(head_token)
           
            # We have an adjective object with an adjective
            #elif token.dep_ in ("nummod", "amod", "npadvmod"):
            #    head_token = token.text
            #    print(head_token)

sent_no = 0
for sent in article_lang_model.sents:
      sent_no += 1
      for token in sent:
            #print(token.text)
            head_token = ""
            dep_date = "2021-01-01"
            # We have an attribute and direct object, so check for subject
            #if token.dep_ in ("attr", "dobj"): 
            #    subj = [w for w in token.head.lefts if w.dep_ == "nsubj"]
            #    if subj:
            #        head_token = subj[0]
            #        print(head_token)
            
            # We have a prepositional object with a preposition
            #elif token.dep_ == "pobj" and token.head.dep_ == "prep":
            #    head_token = token.text
            #    print(head_token)
           
            # We have an adjective object with an adjective
            if token.dep_ in ("nummod", "amod", "npadvmod"):
                head_token = token.text
                print(head_token)

sent_no = 0
for sent in article_lang_model.sents:
      sent_no += 1
      for token in sent:
            #print(token.text)
            head_token = ""
            dep_date = "2021-01-01"
            # We have an attribute and direct object, so check for subject
            if token.dep_ in ("attr", "dobj"): 
                subj = [w for w in token.head.lefts if w.dep_ == "nsubj"]
                if subj:
                    head_token = subj[0]
                    print(head_token)
            
            # We have a prepositional object with a preposition
            elif token.dep_ == "pobj" and token.head.dep_ == "prep":
                head_token = token.text
                print(head_token)
           
            # We have an adjective object with an adjective
            if token.dep_ in ("nummod", "amod", "npadvmod"):
                head_token = token.text
                print(head_token)



# Initialize for testing this code block
ners = []
ners_dep = []
date_ners = []
date_ners_dep = []
"""
dates = ['2018-07-09',
         '2018-W15',
         '2018-02',
         '2018-04-06',
         '2018-W15',
         '2018-02',
         '2015-09',
         '2018-09-27 INTERSECT P5D',
         'FUTURE_REF',
         'FUTURE_REF',
         'PXY',
         'THIS P1D INTERSECT 2018-09-28',
         {'end': 'XXXX-06', 'begin': 'XXXX-04'},
         '2014-03-19',
         '2018-08-02']
"""
FORMAT = '%Y-%m-%d'
def get_simple_date(item, strformat=FORMAT):
    try:
        return (True, datetime.datetime.strptime(item, strformat))
    except (ValueError, TypeError):
        return (False, item)

def get_from_split(is_resolved, item):
    if is_resolved:
        return (is_resolved, item)
    try:
        tokens = item.split(' ')
        are_resolved, items = zip(*(get_simple_date(token) for token in tokens))
        if any(are_resolved):
            # assume one valid token
            result, = (item for item in items if isinstance(item, datetime.datetime))
            return (True, result)
    except (ValueError, AttributeError):
        pass
    return (False, item)

def get_from_no_day(is_resolved, item):
    if is_resolved:
        return (is_resolved, item)
    if not 'W' in item:
        try:
            return (True, datetime.datetime.strptime(f'{item}-01', FORMAT))
        except ValueError:
            pass
    return (False, item)

def get_from_w_date(is_resolved, item):
    if is_resolved:
        return (is_resolved, item)
    if 'W' in item:
        return (True, datetime.datetime.strptime(f'{item}-1', "%Y-W%W-%w"))
    return (is_resolved, item)

def get_token_from_idx(span, index):
  token = span[index]
  print("get_token_from_idx: ", span, index, token)
  return (token)
"""
collection1 = (get_simple_date(item) for item in dates)
collection2 = (get_from_split(*args) for args in collection1)
collection3 = (get_from_no_day(*args) for args in collection2)
collection4 = (get_from_w_date(*args) for args in collection3)
pprint([d for is_resolved, d in collection4 if is_resolved], indent=4)
"""
#article_text = "Net income was $9.4 million compared to the prior year of $2.7 million. Revenue exceeded twelve billion dollars, with a loss of $1b. It was posted yesterday."
#article_text = "March 4th is the wedding date and will occur at the beach."
#article_text = "The wedding will occur at the beach on March 4th after the game."
#article_text = "The wedding was at the beach one week after the game that occured on March 4th."
article_text = "The wedding was at the beach one week after I fell on my head."

sutime = SUTime(mark_time_ranges=True, include_range=True)
sent_no = 0
article_lang_model = lang_model(article_text)
#for doc in article_lang_model:
for sent in article_lang_model.sents:
      sent_no += 1
      print(sent)
      for token in sent:
            #print(token.text)
            head_token = ""
            dep_date = "2021-01-01"
            # We have an attribute and direct object, so check for subject
            if token.dep_ in ("attr", "dobj"): 
                subj = [w for w in token.head.lefts if w.dep_ == "nsubj"]
                if subj:
                    head_token = subj[0]
            # We have a prepositional object with a preposition
            elif token.dep_ == "pobj" and token.head.dep_ == "prep":
                head_token = token.head.head
            # We have an adjective object with an adjective
            elif token.dep_ in ("nummod", "amod", "npadvmod"):
                head_token = token.head
                # TODO print("dobj: ", need token.head's dobj)
                # dobj = [w for w in token.rights if w.dep_ == "dobj"]
                # if
                # print(head_token)
            
            if head_token:
              ners_dep.append([head_token, token])
          
#            if head_token and token.ent_type_ == "DATE":
            if 1: 
#              su = json.loads(sutime.parse(sent.text))
              
              ##############################
              # Emily's function call replaces this block
              su = sutime.parse(sent.text)
              for s in su:
                print("s: ", s)
                tv = s.get('timex-value')
                start = s.get('start')
                end = s.get('end')
#                print(json.dumps(sutime.parse(test_case), sort_keys=True, indent=4))
#                print(sutime.parse(sent.text))
                isValidDate = True
                try :
                  year,month,day = tv.split('-')
                  datetime.datetime(int(year),int(month),int(day))
                  dep_date = tv
                except ValueError :
                  isValidDate = False
               ##################################
#              date_ners.append([token.text, sent_no])
#              date_ners_dep.append([head_token, token, dep_date])

              #t = get_token_from_idx(sent, start)
              spn = sent[0:].char_span(start,end)
              print("spn: ", spn)
              title = "NONE"     
              for chunk in sent.noun_chunks:
                msg = "not me"
                if chunk.root.dep_ == "nsubj":
                   msg = "USE ME"
                   title = chunk.text

                print("chunkers: ", msg, chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)       
              ##############################
              # Emily's function DF is called here with 'title'
              #####################################