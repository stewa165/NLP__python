# -*- coding: utf-8 -*-
"""Copy of Temporality.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FGdyudbT5y5z-uo_GkBN_xtjDQu74E0k

Timeliness Criteria POC - Analyze Temporality of Article Topics

1. Process article
2. Create BOW
3. NLP Processing
4. Create Topic Words - LDA
5. Create Key Word Vectors
6. Create Topic Name - most_similar
7. Determine Topic Word Score
8. Determine TOPIC Scores
9. Determine Article Scores
10 Visualize

**Backlog**
Need to summarize the article into a timeline - 

Date dependencies are not coming into topic names. May need to somehow Weight the date dependencies so they show in LDA differently

Ensure date NER's dependencies link to topical objects

Test earnings report

Put all steps in a main()

Model Plugin
"""

!pip install spacy[transformers]
!python -m spacy download en_core_web_trf

from transformers import pipeline
unmasker = pipeline('fill-mask', model='bert-base-uncased')
unmasker("Hello I'm a [MASK] model.")

"""Not sure what to do with output in the following block? 
Can I use it in a spacy pipeline?
"""

from transformers import BertTokenizer, BertModel
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained("bert-base-uncased")
text = "Replace me by any text you'd like."
encoded_input = tokenizer(text, return_tensors='pt')
output = model(**encoded_input) 
# what can i do with output?
print(output.to_tuple)

#!pip install -U spacy==2.3.0
#!pip install spacy-transformers
#!python -m spacy download en_trf_bertbaseuncased_lg
!pip list
import spacy
import torch
import numpy
from numpy.testing import assert_almost_equal

is_using_gpu = spacy.prefer_gpu()
if is_using_gpu:
    torch.set_default_tensor_type("torch.cuda.FloatTensor")

nlp = spacy.load('en_trf_bertbaseuncased_lg')
doc = nlp("Here is some text to encode.")
assert doc.tensor.shape == (7, 768)  # Always has one row per token
doc._.trf_word_pieces_  # String values of the wordpieces
doc._.trf_word_pieces  # Wordpiece IDs (note: *not* spaCy's hash values!)
doc._.trf_alignment  # Alignment between spaCy tokens and wordpieces

from spacy_transformers import Transformer, TransformerModel
from spacy_transformers.annotation_setters import null_annotation_setter
from spacy_transformers.span_getters import get_doc_spans
import spacy
from thinc.api import set_gpu_allocator, require_gpu

from transformers import BertTokenizer, BertModel
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained("bert-base-uncased")
text = "Replace me by any text you'd like."
encoded_input = tokenizer(text, return_tensors='pt')
output = model(**encoded_input)
print(output.to_tuple)
# Use the GPU, with memory allocations directed via PyTorch.
# This prevents out-of-memory errors that would otherwise occur from competing
# memory pools.
#set_gpu_allocator("pytorch")
#require_gpu(0)
article_text = "Drugmaker Johnson & Johnson is asking the Supreme Court to review a $2.11 billion jury verdict from Missouri over baby powder it produced that allegedly contained asbestos that caused ovarian cancer. In addition to a vaccine used against the CCP virus, which causes the disease COVID-19, the 135-year-old New Jersey-based company has been known for making a variety of talc-based consumer products such as its iconic baby powder, which is the subject of the litigation. The petition in the case, known as Johnson & Johnson v. Ingham, court file 20-1223, was filed with the Supreme Court on March 4. The verdict came out of a 2018 trial that consolidated the claims of 22 women who alleged the company’s talc powder caused their ovarian cancer. After a six-week trial, a St. Louis jury originally ordered the company to pay $4.69 billion, but in 2020, the Missouri Court of Appeals lowered the sum to $2.11 billion, trade publication Fierce Pharma reported at the time. Also last year, the company stopped selling talc powders in the United States. That court found that the plaintiffs “proved with convincing clarity” that Johnson & Johnson “engaged in outrageous conduct because of an evil motive or reckless indifference.” Company officials, according to the court, “discussed the presence of asbestos in their talc in internal memoranda for several decades; avoided adopting more accurate measures for detecting asbestos and influenced the industry to do the same; attempted to discredit those scientists publishing studies unfavorable to their products; and did not eliminate talc from the products and use cornstarch instead because it would be more costly to do so.” Johnson & Johnson argues that bad science was relied on during the trial and that the company was denied due process. The trial was “fundamentally flawed,” and “numerous legal errors allowed a faulty presentation of the facts, resulting in an incorrect verdict and arbitrary and disproportionate damages,” the company said in a statement supplied by its attorneys. The verdict is “at odds with decades of independent scientific evaluations confirming Johnson’s Baby Powder is safe, is not contaminated by asbestos and does not cause cancer.” The $2.1 billion award in the case “is so unmoored from any notion of proportionality or malice that reversal is warranted based solely on the arbitrary size of the jury’s damages award,” Cory L. Andrews, general counsel and vice president of litigation for the Washington Legal Foundation, said in a statement. “The legal inconsistencies in this case highlight some of the worst abuses in our civil justice system today,” Tiger Joyce, president of the American Tort Reform Association, said in a statement. “The City of St. Louis is regularly named among the worst ‘Judicial Hellholes’ in the country and it’s no wonder. The court allowed nearly two dozen plaintiffs from different states who all had varying circumstances to be joined together in a friendly venue of their lawyers’ choosing. The trial lawyers then presented questionable scientific evidence as though it were fact, unfairly prejudicing the jury in the process.” Johnson & Johnson argues in its petition that it has been victimized by plaintiffs’ lawyers, who have abused the legal system. “Today, confusion reigns in the lower courts over the due process boundaries of mass trials—and whether jury instructions by themselves are a sufficient antidote to the jury confusion and prejudice mass trials cause. The Court should intervene here to curb due-process abuses in mass-tort suits and ensure that state courts give mass-tort defendants the same rights as everyone else.” The company reiterates that its talc products are safe for consumer use. Federal regulators and respected health organizations reject calls for warnings on talc and “comprehensive epidemiological studies tracking tens of thousands of talc users have found no meaningful association between cosmetic talc use and ovarian cancer.” The Food and Drug Administration, National Cancer Institute, and American Cancer Society have all reached the same conclusion, the company states. “Yet some plaintiffs’ lawyers have struck on a winning formula: They first canvass the country for women who were both diagnosed with ovarian cancer and among the millions who used Petitioners’ talc products. They then select a jurisdiction where out-of-state plaintiffs can be consolidated with in-state plaintiffs for a single mass trial. They put dozens of plaintiffs on the stand to discuss their experiences with cancer, and the jury awards billions of dollars in punitive damages supposedly to punish Petitioners. “Lawyers can then follow this script and file the same claims with new plaintiffs and seek new outsized awards, over and over again.” It’s unclear when the Supreme Court will rule on whether to hear the company’s appeal. Thomas C. Goldstein, counsel of record for the consumers suing Johnson & Johnson, declined to comment to The Epoch Times on the pending litigation." 

nlp = spacy.load("en_core_web_trf")
for doc in nlp.pipe([article_text]):
    tokvecs = doc._.trf_data.tensors[-1]

lang_model = Transformer(
    nlp.vocab,
    model,
    set_extra_annotations=null_annotation_setter,
    max_batch_items=4096,
)
"""
lang_model = Transformer(
    nlp.vocab,
    TransformerModel(
        "bert-base-uncasedxxx",
#        "bert-base-cased",
        get_spans=get_doc_spans,
        tokenizer_config={"use_fast": True},
    ),
    set_extra_annotations=null_annotation_setter,
    max_batch_items=4096,
)
"""
for x in doc.sents:
  print(x)
print(tokvecs.data.shape)

"""Initialize Environment"""

# Install/Setup Spacy Components and Language Model
# IF NEEDED
#Functions from external python
#%run '/content/drive/My Drive/Colab Notebooks/functions.py'
!pip install -U spacy 

# Don't forget to restart runtime
!python -m spacy download en_core_web_lg

import spacy

# Install/Setup Gensim Components
import gensim, logging
from gensim.models import Word2Vec
from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors

# Install sutime from Stanford NLP library
!pip install sutime
!sudo apt-get install maven
# Install Java dependencies
!mvn dependency:copy-dependencies -DoutputDirectory=./jars -f $(python3 -c 'import importlib; import pathlib; print(pathlib.Path(importlib.util.find_spec("sutime").origin).parent / "pom.xml")')
import datetime
from sutime import SUTime

logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
 
# Setup Language Model
lang_model = spacy.load("en_core_web_lg")
# Merge noun phrases and entities for easier analysis
lang_model.add_pipe('merge_entities')
#lang_model.add_pipe('merge_noun_chunks')
#lang_model.add_pipe(lang_model.create_pipe('merge_entities'))
#lang_model.add_pipe(lang_model.create_pipe('merge_noun_chunks'))
lang_model.add_pipe('sentencizer')
# Article Data Structures
article_text = []
article_paragraphs = []
article_sentences = []
artilce_bow = []
artilce_bow_nlp = []

# NLP Data Structures
ners = []
ners_dep = []
date_ners = []
date_ners_dep = []

# Topic Data Structures
topic_count = 5
# topic name list with each topic name having a topic words list topics[[]], i.e. nested lists
topics = []
topic_names = []

"""Process article (Beautiful Soup)

https://www.theepochtimes.com/johnson-johnson-appeals-2-billion-cancer-verdict-over-baby-powder-to-supreme-court_3728718.html
"""

import urllib.request, urllib.error, urllib.parse
import gensim, logging 
from bs4 import BeautifulSoup

 
# url = 'https://www.politico.com/news/2021/03/06/new-york-governor-potential-democratic-candidates-473916'
# url = 'https://www.theepochtimes.com/johnson-johnson-appeals-2-billion-cancer-verdict-over-baby-powder-to-supreme-court_3728718.html'
url = 'https://www.reuters.com/article/us-johnson-johnson-talc-ruling/johnson-johnson-fails-to-overturn-2-12-billion-baby-powder-verdict-plans-supreme-court-appeal-idUSKBN27J2N4'

response = urllib.request.urlopen(url)
webContent = response.read()
# Put html in beautysoup
soup = BeautifulSoup(webContent)

whitelist = [
  'p'
]

#soup find_all --- article_text list by <p> (html paragraph) 
#article_text = [t for t in soup.find_all(text=True) if t.parent.name in whitelist]
#article_text = [
#"Drugmaker Johnson & Johnson is asking the Supreme Court to review a $2.11 billion jury verdict from Missouri over baby powder it produced that allegedly contained asbestos that caused ovarian cancer. In addition to a vaccine used against the CCP virus, which causes the disease COVID-19, the 135-year-old New Jersey-based company has been known for making a variety of talc-based consumer products such as its iconic baby powder, which is the subject of the litigation. The petition in the case, known as Johnson & Johnson v. Ingham, court file 20-1223, was filed with the Supreme Court on March 4. The verdict came out of a 2018 trial that consolidated the claims of 22 women who alleged the company’s talc powder caused their ovarian cancer. After a six-week trial, a St. Louis jury originally ordered the company to pay $4.69 billion, but in 2020, the Missouri Court of Appeals lowered the sum to $2.11 billion, trade publication Fierce Pharma reported at the time. Also last year, the company stopped selling talc powders in the United States. That court found that the plaintiffs “proved with convincing clarity” that Johnson & Johnson “engaged in outrageous conduct because of an evil motive or reckless indifference.” Company officials, according to the court, “discussed the presence of asbestos in their talc in internal memoranda for several decades; avoided adopting more accurate measures for detecting asbestos and influenced the industry to do the same; attempted to discredit those scientists publishing studies unfavorable to their products; and did not eliminate talc from the products and use cornstarch instead because it would be more costly to do so.” Johnson & Johnson argues that bad science was relied on during the trial and that the company was denied due process. The trial was “fundamentally flawed,” and “numerous legal errors allowed a faulty presentation of the facts, resulting in an incorrect verdict and arbitrary and disproportionate damages,” the company said in a statement supplied by its attorneys. The verdict is “at odds with decades of independent scientific evaluations confirming Johnson’s Baby Powder is safe, is not contaminated by asbestos and does not cause cancer.” The $2.1 billion award in the case “is so unmoored from any notion of proportionality or malice that reversal is warranted based solely on the arbitrary size of the jury’s damages award,” Cory L. Andrews, general counsel and vice president of litigation for the Washington Legal Foundation, said in a statement. “The legal inconsistencies in this case highlight some of the worst abuses in our civil justice system today,” Tiger Joyce, president of the American Tort Reform Association, said in a statement. “The City of St. Louis is regularly named among the worst ‘Judicial Hellholes’ in the country and it’s no wonder. The court allowed nearly two dozen plaintiffs from different states who all had varying circumstances to be joined together in a friendly venue of their lawyers’ choosing. The trial lawyers then presented questionable scientific evidence as though it were fact, unfairly prejudicing the jury in the process.” Johnson & Johnson argues in its petition that it has been victimized by plaintiffs’ lawyers, who have abused the legal system. “Today, confusion reigns in the lower courts over the due process boundaries of mass trials—and whether jury instructions by themselves are a sufficient antidote to the jury confusion and prejudice mass trials cause. The Court should intervene here to curb due-process abuses in mass-tort suits and ensure that state courts give mass-tort defendants the same rights as everyone else.” The company reiterates that its talc products are safe for consumer use. Federal regulators and respected health organizations reject calls for warnings on talc and “comprehensive epidemiological studies tracking tens of thousands of talc users have found no meaningful association between cosmetic talc use and ovarian cancer.” The Food and Drug Administration, National Cancer Institute, and American Cancer Society have all reached the same conclusion, the company states. “Yet some plaintiffs’ lawyers have struck on a winning formula: They first canvass the country for women who were both diagnosed with ovarian cancer and among the millions who used Petitioners’ talc products. They then select a jurisdiction where out-of-state plaintiffs can be consolidated with in-state plaintiffs for a single mass trial. They put dozens of plaintiffs on the stand to discuss their experiences with cancer, and the jury awards billions of dollars in punitive damages supposedly to punish Petitioners. “Lawyers can then follow this script and file the same claims with new plaintiffs and seek new outsized awards, over and over again.” It’s unclear when the Supreme Court will rule on whether to hear the company’s appeal. Thomas C. Goldstein, counsel of record for the consumers suing Johnson & Johnson, declined to comment to The Epoch Times on the pending litigation." 
#]
article_text = "Drugmaker Johnson & Johnson is asking the Supreme Court to review a $2.11 billion jury verdict from Missouri over baby powder it produced that allegedly contained asbestos that caused ovarian cancer. In addition to a vaccine used against the CCP virus, which causes the disease COVID-19, the 135-year-old New Jersey-based company has been known for making a variety of talc-based consumer products such as its iconic baby powder, which is the subject of the litigation. The petition in the case, known as Johnson & Johnson v. Ingham, court file 20-1223, was filed with the Supreme Court on March 4. The verdict came out of a 2018 trial that consolidated the claims of 22 women who alleged the company’s talc powder caused their ovarian cancer. After a six-week trial, a St. Louis jury originally ordered the company to pay $4.69 billion, but in 2020, the Missouri Court of Appeals lowered the sum to $2.11 billion, trade publication Fierce Pharma reported at the time. Also last year, the company stopped selling talc powders in the United States. That court found that the plaintiffs “proved with convincing clarity” that Johnson & Johnson “engaged in outrageous conduct because of an evil motive or reckless indifference.” Company officials, according to the court, “discussed the presence of asbestos in their talc in internal memoranda for several decades; avoided adopting more accurate measures for detecting asbestos and influenced the industry to do the same; attempted to discredit those scientists publishing studies unfavorable to their products; and did not eliminate talc from the products and use cornstarch instead because it would be more costly to do so.” Johnson & Johnson argues that bad science was relied on during the trial and that the company was denied due process. The trial was “fundamentally flawed,” and “numerous legal errors allowed a faulty presentation of the facts, resulting in an incorrect verdict and arbitrary and disproportionate damages,” the company said in a statement supplied by its attorneys. The verdict is “at odds with decades of independent scientific evaluations confirming Johnson’s Baby Powder is safe, is not contaminated by asbestos and does not cause cancer.” The $2.1 billion award in the case “is so unmoored from any notion of proportionality or malice that reversal is warranted based solely on the arbitrary size of the jury’s damages award,” Cory L. Andrews, general counsel and vice president of litigation for the Washington Legal Foundation, said in a statement. “The legal inconsistencies in this case highlight some of the worst abuses in our civil justice system today,” Tiger Joyce, president of the American Tort Reform Association, said in a statement. “The City of St. Louis is regularly named among the worst ‘Judicial Hellholes’ in the country and it’s no wonder. The court allowed nearly two dozen plaintiffs from different states who all had varying circumstances to be joined together in a friendly venue of their lawyers’ choosing. The trial lawyers then presented questionable scientific evidence as though it were fact, unfairly prejudicing the jury in the process.” Johnson & Johnson argues in its petition that it has been victimized by plaintiffs’ lawyers, who have abused the legal system. “Today, confusion reigns in the lower courts over the due process boundaries of mass trials—and whether jury instructions by themselves are a sufficient antidote to the jury confusion and prejudice mass trials cause. The Court should intervene here to curb due-process abuses in mass-tort suits and ensure that state courts give mass-tort defendants the same rights as everyone else.” The company reiterates that its talc products are safe for consumer use. Federal regulators and respected health organizations reject calls for warnings on talc and “comprehensive epidemiological studies tracking tens of thousands of talc users have found no meaningful association between cosmetic talc use and ovarian cancer.” The Food and Drug Administration, National Cancer Institute, and American Cancer Society have all reached the same conclusion, the company states. “Yet some plaintiffs’ lawyers have struck on a winning formula: They first canvass the country for women who were both diagnosed with ovarian cancer and among the millions who used Petitioners’ talc products. They then select a jurisdiction where out-of-state plaintiffs can be consolidated with in-state plaintiffs for a single mass trial. They put dozens of plaintiffs on the stand to discuss their experiences with cancer, and the jury awards billions of dollars in punitive damages supposedly to punish Petitioners. “Lawyers can then follow this script and file the same claims with new plaintiffs and seek new outsized awards, over and over again.” It’s unclear when the Supreme Court will rule on whether to hear the company’s appeal. Thomas C. Goldstein, counsel of record for the consumers suing Johnson & Johnson, declined to comment to The Epoch Times on the pending litigation." 

#nlp = English()
#lang_model.add_pipe(lang_model.create_pipe('sentencizer')) # updated
article_lang_model = lang_model(article_text)
#sentences = [sent.string.strip() for sent in doc.sents]
article_sentences = []
for sent in article_lang_model.sents:
  article_sentences.append(sent)
for s in article_sentences:
  print(s)

"""Create BOW's (Gensim)"""

# Commented out IPython magic to ensure Python compatibility.
## little gensim
#pip install --upgrade gensim
### pip install --upgrade pyLDAvis
# %pip install pyLDAvis==2.1.2
import nltk
# python3 -m spacy download en
nltk.download('stopwords')
import re
import warnings
import numpy as np
import pandas as  pd
from pprint import pprint# Gensim
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel# spaCy for preprocessing
import spacy# Plotting tools
import pyLDAvis
#import pyLDAvis.gensim_models
import pyLDAvis.gensim
#import pyLDAvis.gensim as gensimvis
import matplotlib.pyplot as plt
# %matplotlib inline
# NLTK Stop words
from nltk.corpus import stopwords
stop_words = stopwords.words('english')
stop_words.extend(['from', 'subject', 're', 'edu', 'use'])
# LoadDataset
#text = "I seen all good people turn their heads each day so satisfied I'm on my way.  Take a straight and stronger course to the center of your mind"
#print(article_text)
data = article_sentences
def Convert(string): 
    li = list(string.split(" ")) 
    return li

#Convert(data)    
#print(data)
def sent_to_words(sentences):
  for sentence in article_sentences:
     yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))            #deacc=True removes punctuations
#    yield(gensim.utils.simple_preprocess(data, deacc=False, min_len=2, max_len=15))
data_words = list(sent_to_words(data))
  
print(*data_words)
# Build the bigram and trigram models
bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.
trigram = gensim.models.Phrases(bigram[data_words], threshold=100)
# Faster way to get a sentence clubbed as a trigram/bigram
bigram_mod = gensim.models.phrases.Phraser(bigram)
trigram_mod = gensim.models.phrases.Phraser(trigram)
# See trigram example
#print(trigram_mod[bigram_mod[data_words[0]]])
# Define function for stopwords, bigrams, trigrams and lemmatization
def remove_stopwords(texts):
    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]
 
def make_bigrams(texts):
    return [bigram_mod[doc] for doc in texts]
 
def make_trigrams(texts):
    return [trigram_mod[bigram_mod[doc]] for doc in texts]
 
def lemmatization(texts):
    """https://spacy.io/api/annotation"""
    texts_out = []
    for sent in texts:
        doc = lang_model(" ".join(sent))
        texts_out.append([token.lemma_ for token in doc])
    return texts_out
    
# Remove Stop Words
data_words_nostops = remove_stopwords(data_words)
#print(data_words_nostops)
 
# Form Bigrams
data_words_bigrams = make_bigrams(data_words_nostops)
##print(data_words_bigrams)

# Initialize spacy 'en' model, keeping only tagger component (for efficiency)
# python3 -m spacy download en
#spacy.cli.download("en_core_web_sm")
#lang_model = spacy.load('en', disable=['parser', 'ner'])
#lang_model = spacy.load("en_core_web_sm")
 
# Do lemmatization keeping only noun, adj, vb, adv
#data_lemmatized = lemmatization(data_words_bigrams)
 
#print(data_lemmatized[:1])
# Create Dictionary
id2word = corpora.Dictionary(data_words_bigrams)
# Create Corpus
#article_bow = data_words_nostops
article_bow = data_words_bigrams
#article_bow = data_lemmatized
print(article_bow)

print(article_bow)

"""NLP Processing (Spacy)"""

# Initialize for testing this code block
ners = []
ners_dep = []
date_ners = []
date_ners_dep = []
"""
dates = ['2018-07-09',
         '2018-W15',
         '2018-02',
         '2018-04-06',
         '2018-W15',
         '2018-02',
         '2015-09',
         '2018-09-27 INTERSECT P5D',
         'FUTURE_REF',
         'FUTURE_REF',
         'PXY',
         'THIS P1D INTERSECT 2018-09-28',
         {'end': 'XXXX-06', 'begin': 'XXXX-04'},
         '2014-03-19',
         '2018-08-02']
"""
FORMAT = '%Y-%m-%d'
def get_simple_date(item, strformat=FORMAT):
    try:
        return (True, datetime.datetime.strptime(item, strformat))
    except (ValueError, TypeError):
        return (False, item)

def get_from_split(is_resolved, item):
    if is_resolved:
        return (is_resolved, item)
    try:
        tokens = item.split(' ')
        are_resolved, items = zip(*(get_simple_date(token) for token in tokens))
        if any(are_resolved):
            # assume one valid token
            result, = (item for item in items if isinstance(item, datetime.datetime))
            return (True, result)
    except (ValueError, AttributeError):
        pass
    return (False, item)

def get_from_no_day(is_resolved, item):
    if is_resolved:
        return (is_resolved, item)
    if not 'W' in item:
        try:
            return (True, datetime.datetime.strptime(f'{item}-01', FORMAT))
        except ValueError:
            pass
    return (False, item)

def get_from_w_date(is_resolved, item):
    if is_resolved:
        return (is_resolved, item)
    if 'W' in item:
        return (True, datetime.datetime.strptime(f'{item}-1', "%Y-W%W-%w"))
    return (is_resolved, item)
"""
collection1 = (get_simple_date(item) for item in dates)
collection2 = (get_from_split(*args) for args in collection1)
collection3 = (get_from_no_day(*args) for args in collection2)
collection4 = (get_from_w_date(*args) for args in collection3)
pprint([d for is_resolved, d in collection4 if is_resolved], indent=4)
"""
"""
article_text = "Net income was $9.4 million compared to the prior year of $2.7 million. Revenue exceeded twelve billion dollars, with a loss of $1b. It was posted yesterday."
"""
sutime = SUTime(mark_time_ranges=True, include_range=True)
sent_no = 0
#for doc in lang_model.pipe(article_text):
#for doc in article_lang_model:
for sent in article_lang_model.sents:
      sent_no += 1
      for token in sent:
            #print(token.text)
            head_token = ""
            dep_date = "2021-01-01"
            # We have an attribute and direct object, so check for subject
            if token.dep_ in ("attr", "dobj"): 
                subj = [w for w in token.head.lefts if w.dep_ == "nsubj"]
                if subj:
                    head_token = subj[0]
            # We have a prepositional object with a preposition
            elif token.dep_ == "pobj" and token.head.dep_ == "prep":
                head_token = token.head.head
            # We have an adjective object with an adjective
            elif token.dep_ in ("nummod", "amod", "npadvmod"):
                head_token = token.head
                # TODO print("dobj: ", need token.head's dobj)
                # dobj = [w for w in token.rights if w.dep_ == "dobj"]
                # if
                # print(head_token)
            
            if head_token:
              ners_dep.append([head_token, token])
          
            if head_token and token.ent_type_ == "DATE":
#              su = json.loads(sutime.parse(sent.text))
              su = sutime.parse(sent.text)
              for s in su:
                print("s: ", s)
                tv = s.get('timex-value')
#                t = s.get('DATE')
#                print(json.dumps(sutime.parse(test_case), sort_keys=True, indent=4))
#                print(sutime.parse(sent.text))
                isValidDate = True
                try :
                  year,month,day = tv.split('-')
                  datetime.datetime(int(year),int(month),int(day))
                  dep_date = tv
                except ValueError :
                  isValidDate = False

              date_ners.append([token.text, sent_no])
              date_ners_dep.append([head_token, token, dep_date])

#NER iterator
for ent in article_lang_model.ents:
  ners.append([ent.text, ent.label_])

# Need to convert date NER to a datetime
# Determine date range(s); may be multiple ranges if article jumps far in the past
# Create datetime window for each date NER's object and put in array

print("Date NERs Dep")
val_list = list(id2word.values())
for t in date_ners_dep:
  try:
    n = val_list.index(t[0].text)
    print(t[0].text, '-->', t[1], "date: ", t[2], " n: ", n)
  except ValueError:
    pass
#  print(t[0].text, '-->', t[1])
'''
print("NERs Dep")
for t in ners_dep:
  print(t[0], '-->', t[1])

print("Date NERs")
#for t in date_ners:
#  print(t[0], '-->', t[1])

print("NERs")
for t in ners:
  print("NER: ", t[0], t[1])
print("Sentences")
for sent in article_lang_model.sents:
    print(sent.text)
'''

"""Stanford CoreNLP sutime - for focused testing"""

# Ideally, create a virtual environment before installing any dependencies
import json
from sutime import SUTime

#if __name__ == '__main__':
if 1:
    test_case = 'I need a desk for tomorrow from 2pm to 3pm. trial yesterday. 3 weeks before March 4, 2020. Today from 3:15 to 6:28.'
    sutime = SUTime(mark_time_ranges=True, include_range=True)
    print(json.dumps(sutime.parse(test_case), sort_keys=True, indent=4))

"""Get Topics Words (Gensim LDA)"""

topic_count = 7
# Term Document Frequency
corpus = [id2word.doc2bow(article_text) for article_text in article_bow]
#corpus = [id2word.doc2bow(['company','filed','trial','discussed','abuses','reigns','lowered', 'stopped', 'odds'], allow_update=True)]
print("id2word: ", id2word)
print("Corpus: ", corpus)
print("article_bow: ", article_bow)
#for x in id2word:
#  print("x: ", id2word[x])
#print("Corpus ",corpus[:1])
#[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]
#print("id2word: ", id2word)
warnings.filterwarnings("ignore")
lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,
                                           id2word=id2word,
                                           num_topics=topic_count,
                                           random_state=100,
                                           update_every=1,
                                           chunksize=100,
                                           passes=10,
                                           alpha='auto',
                                           per_word_topics=True)
#ts = lda_model.get_document_topics(corpus)
#ts = lda_model.get_topics()
topics = []
for i in range(topic_count):
  words = []
  ts = lda_model.get_topic_terms(i)
  for t in ts:
    words.append([i, t, id2word.get(t[0])])
  topics.append(words)

#print(topics)
for t in topics:
  for x in t:
    print(x[0], x[1], x[2])

"""Create Key Word Vectors from Language Model (Gensim)"""

#w2vmodel = Word2Vec(lang_model)
wordList =[]
vectorList = []
for key, vector in lang_model.vocab.vectors.items():
    wordList.append(lang_model.vocab.strings[key] )
    vectorList.append(vector)

kv = WordEmbeddingsKeyedVectors(lang_model.vocab.vectors_length)
kv.add(wordList, vectorList)

"""Get Topic Name (Gensim most_similar)"""

topic_names = [] # Should be GLOBAL
topic_names_dates = []
topic_names_durations = []
t_count = 0
if 0: # for topics
  while t_count < topic_count: 
    tn_words = []
#    print(topics[0][0][0])
    for x in topics[t_count]:
#        print(x[0], x[1], x[2])
        tn_words.append(x[2])
    t_count += 1
#   tn_words.append("the Missouri Court of Appeals")
    print(tn_words)
    tw = kv.most_similar_cosmul(positive=tn_words)
    print("tw", tw)
    topic_names.append(tw[0][0])
    # TODO: need to get dates for each topic name; durations could be string length
    # topic_names_dates = start, mid, end
    topic_names_dates.append([['6','2014'], ['8','2014'], ['8','2014']])
    topic_names_durations.append([0.2, 1.0])
else:
  #filed --> March 4 date:  2021-03-04  n:  43
  for x in date_ners_dep:
    topic_names.append(x[0].text)
    topic_names_dates.append(x[2])
    topic_names_durations.append([0.2, 1.0])

print("topic_names", topic_names)
print("topic_names_dates", topic_names_dates)
print("topic_names_durations", topic_names_durations)

#print(kv.most_similar("basketball"))
#topicname = kv.most_similar(positive=['woman', 'king'], negative=['man'])
#topicname = kv.similar_by_word("talcum")

#topicname = kv.most_similar_cosmul(positive=['strings', 'keys', 'bridge', 'pickup', 'music'], negative=['strings'])
#topicname2 = kv.most_similar(positive=['strings', 'keys', 'bridge', 'pickup', 'music'])
#print(topicname)
#print(topicname2)

"""Gantt Chart"""

"""
Creates a simple Gantt chart
http://www.clowersresearch.com/main/gantt-charts-in-matplotlib/
Adapted from https://bitbucket.org/DBrent/phd/src/1d1c5444d2ba2ee3918e0dfd5e886eaeeee49eec/visualisation/plot_gantt.py
BHC 2014
"""
 
import datetime as dt
import matplotlib.pyplot as plt
import matplotlib.font_manager as font_manager
import matplotlib.dates
from matplotlib.dates import MONTHLY, DateFormatter, rrulewrapper, RRuleLocator
 
from pylab import *
 
def create_date(month,year):
#"""Creates the date"""
  date = dt.datetime(int(year), int(month), 1)
  mdate = matplotlib.dates.date2num(date)
  return mdate
 
# Data
 
#pos = arange(0.5,5.5,0.5)
pos = arange(1.0,5.5,0.5)
 
ylabels = []
#for t in topic_names:
for i,t in enumerate(topic_names):
  s = t + '-' + str(i)
  ylabels.append(s)
#print("ylabels", ylabels)   
'''
ylabels.append('Johnson’s Baby Powder')
ylabels.append('Hardware Construction')
ylabels.append('Integrate and Test Laser Source')
ylabels.append('Objective #1')
ylabels.append('Objective #2')
ylabels.append('Present at ASMS')
ylabels.append('Present Data at Gordon Conference')
ylabels.append('Manuscripts and Final Report')
'''

effort = []
for d in topic_names_durations:
  effort.append(d)
'''
  print("topic_names_durations: ", d)
effort.append([0.2, 1.0])
effort.append([0.2, 1.0])
effort.append([0.2, 1.0])
effort.append([0.3, 0.75])
effort.append([0.25, 0.75])
effort.append([0.3, 0.75])
effort.append([0.5, 0.5])
effort.append([0.7, 0.4])
'''
customDates = []
#for i in range(0, topic_count-1):
for d in topic_names_dates:
  print("topic_names_dates: ", d)
  y,m,d = d.split('-')
  customDates.append([create_date(m, y),create_date(12, 2021),create_date(12, 2021)])
print("customDates", customDates)
'''
customDates.append([create_date(5,2014),create_date(6,2014), create_date(6,2014)])
customDates.append([create_date(6,2014),create_date(8,2014),create_date(8,2014)])
customDates.append([create_date(7,2014),create_date(9,2014),create_date(9,2014)])
customDates.append([create_date(10,2014),create_date(3,2015),create_date(3,2015)])
customDates.append([create_date(2,2015),create_date(6,2015),create_date(6,2015)])
customDates.append([create_date(5,2015),create_date(6,2015),create_date(6,2015)])
customDates.append([create_date(6,2015),create_date(7,2015),create_date(7,2015)])
customDates.append([create_date(4,2015),create_date(8,2015),create_date(8,2015)])
'''

task_dates = {}
for i,task in enumerate(ylabels):
  print("task: ", task, customDates[i])
  task_dates[task] = customDates[i]

#  task_dates[task] = customDates[i][0], customDates[i][1]
# task_dates['Climatology'] = [create_date(5,2014),create_date(6,2014),create_date(10,2013)]
# task_dates['Structure'] = [create_date(10,2013),create_date(3,2014),create_date(5,2014)]
# task_dates['Impacts'] = [create_date(5,2014),create_date(12,2014),create_date(2,2015)]
# task_dates['Thesis'] = [create_date(2,2015),create_date(5,2015)]
 
# Initialise plot
fig = plt.figure()
# ax = fig.add_axes([0.15,0.2,0.75,0.3]) #[left,bottom,width,height]
ax = fig.add_subplot(111)
 
# Plot the data
print("task_dates: ", task_dates) 

#start_date,mid_date, end_date = task_dates[ylabels[0]]
start_date,mid_date, end_date = [create_date(10,2020),create_date(12,2021),create_date(12,2021)]
ax.barh(0.5, end_date - start_date, left=start_date, height=0.3, align='center', color='yellow', alpha = 0.75)
#ax.barh(0.45, (end_date - start_date)*effort[0][0], left=start_date, height=0.1, align='center', color='red', alpha = 0.75, label = "PI Effort")
#ax.barh(0.55, (end_date - start_date)*effort[0][1], left=start_date, height=0.1, align='center', color='blue', alpha = 0.75, label = "Student Effort")
#ax.barh(0.65, (end_date - start_date)*effort[0][1], left=start_date, height=0.1, align='center', color='green', alpha = 0.75, label = "Effort")

#for i in range(0,len(ylabels)-1):
for i in range(0,len(ylabels)):
  #labels = ['Analysis','Reporting'] if i == 1 else [None,None]
#  start_date,mid_date,end_date = task_dates[ylabels[i+1]]
#  piEffort, studentEffort = effort[i+1]
  start_date,mid_date,end_date = task_dates[ylabels[i]]
  piEffort, studentEffort = effort[i]
  ax.barh((i*0.5)+1.0, mid_date - start_date, left=start_date, height=0.3, align='center', color='yellow', alpha = 0.75)
  ax.barh((i*0.5)+1.0-0.05, (mid_date - start_date)*piEffort, left=start_date, height=0.1, align='center', color='red', alpha = 0.75)
#  ax.barh((i*0.5)+1.0+0.05, (mid_date - start_date)*studentEffort, left=start_date, height=0.1, align='center', color='blue', alpha = 0.75)
#  ax.barh((i*0.5)+1.0, end_date - mid_date, left=mid_date, height=0.3, align='center',label=labels[1], color='yellow')
print("len", len(ylabels))
#label = ax.annotate("hellow", xy=(10, 1), xytext=(1, 0), xycoords='axes points', horizontalalignment='left', verticalalignment='center') 

# Format the y-axis
locsy, labelsy = yticks(pos,ylabels)
plt.setp(labelsy, fontsize = 14)
 
# Format the x-axis
ax.axis('tight')
#ax.set_ylim(ymin = -0.1, ymax = 4.5)
ax.set_ylim(ymin = -0.1, ymax = 5.5)
ax.grid(color = 'g', linestyle = ':')
 
ax.xaxis_date() #Tell matplotlib that these are dates...
 
rule = rrulewrapper(MONTHLY, interval=1)
#rule = rrulewrapper(YEARLY, interval=1)
loc = RRuleLocator(rule)
formatter = DateFormatter("%b '%y")
 
ax.xaxis.set_major_locator(loc)
ax.xaxis.set_major_formatter(formatter)
labelsx = ax.get_xticklabels()
print("labelsx: ", labelsx)
#plt.setp(labelsx, rotation=30, fontsize=12)
plt.setp(labelsx, rotation=30, fontsize=10)

# Format the legend
font = font_manager.FontProperties(size='small')
ax.legend(loc=1,prop=font)
 
# Finish up
ax.invert_yaxis()
fig.autofmt_xdate()
#plt.savefig('gantt.svg')
plt.show()

"""Spacy Visualization"""

# POS DIAGRAM Visualization
# Copy/paste into https://codebeautify.org/htmlviewer/
import spacy
from spacy import displacy

#lang_model = spacy.load("en_core_web_sm")
#doc = lang_model("After a six-week trial, a St. Louis jury originally ordered the company to pay $4.69 billion, but in 2020, the Missouri Court of Appeals lowered the sum to $2.11 billion, trade publication Fierce Pharma reported at the time. Also last year, the company stopped selling talc powders in the United States.")
#displacy.render(doc, style="dep")
displacy.render(article_lang_model, style="dep")

"""Gensim Visualization (perplexity and coherence)"""

doc_lda = lda_model[corpus]
# Compute Perplexity
print('\nPerplexity: ', lda_model.log_perplexity(corpus))
# a measure of how good the model is. lower the better.
 
# Compute Coherence Score
coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')
coherence_lda = coherence_model_lda.get_coherence()
print('\nCoherence Score: ', coherence_lda)

# Print the keyword of topics
topics = lda_model.get_document_topics(corpus)
print("TOPICS:")
#for topic in topics:
#  print(topic)
#print("TOPICS: ", topics)
#print("TOPICS: ", doc_lda)
#print("TOPICS: ", lda_model.print_topics())

# Visualize the topics
pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)
vis